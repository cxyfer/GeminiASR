import os
import re
import time
import argparse
import tempfile
import logging
import random
import threading
import concurrent.futures
import collections

import moviepy.editor as mp
from google import genai
from google.genai import types
from langchain.prompts import PromptTemplate
from dotenv import load_dotenv
from utils.api_key_manager import key_manager

load_dotenv()

# To ensure thread safety in a multi-threaded environment, create a thread-local storage
thread_local = threading.local()

# Create a logging lock to ensure mutual exclusion of log output
log_lock = threading.RLock()

# Create a dedicated logger instance
logger = logging.getLogger('gemini_asr')


def setup_logging(level=logging.INFO):
    """Set up logging format and level."""

    # Create a custom log handler to ensure mutual exclusion in a multi-threaded environment
    class ThreadSafeHandler(logging.StreamHandler):
        def emit(self, record):
            with log_lock:
                super().emit(record)

    # Color definitions
    COLORS = {
        'DEBUG': '\033[36m',  # Cyan
        'INFO': '\033[32m',  # Green
        'WARNING': '\033[33m',  # Yellow
        'ERROR': '\033[31m',  # Red
        'CRITICAL': '\033[41m',  # Red background
        'RESET': '\033[0m'  # Reset color
    }

    # Custom formatter to set color based on log level
    class ColoredFormatter(logging.Formatter):
        def format(self, record):
            levelname = record.levelname
            if levelname in COLORS:
                record.levelname = f"{COLORS[levelname]}{levelname}{COLORS['RESET']}"
                record.msg = f"{COLORS[levelname]}{record.msg}{COLORS['RESET']}"
            return super().format(record)

    # Remove any existing handlers
    for handler in logger.handlers[:]:
        logger.removeHandler(handler)

    # Create a new thread-safe handler
    handler = ThreadSafeHandler()
    formatter = ColoredFormatter('%(asctime)s - %(levelname)s - %(threadName)s - %(message)s',
                                 datefmt='%Y-%m-%d %H:%M:%S')
    handler.setFormatter(formatter)

    # Configure our dedicated logger
    logger.setLevel(level)
    logger.addHandler(handler)

    # Prevent log propagation to the root logger, so logs from other libraries won't be output through our handler
    logger.propagate = False

    # Set the log level of other libraries to WARNING or higher to reduce noise
    logging.getLogger().setLevel(logging.WARNING)

    logger.debug(f"Logging system initialized, level: {logging.getLevelName(level)}")


def split_media(media_path, temp_dir, duration=300):
    """Splits a video or audio file into smaller segments."""
    is_video = True if media_path.lower().endswith(('.mp4', '.avi', '.mov', '.mkv')) else False
    file_type = "video" if is_video else "audio"
    logger.debug(f"Starting to split {file_type} {media_path}, segment duration: {duration} seconds")

    # Load media based on file type
    if is_video:
        media = mp.VideoFileClip(media_path)
    else:
        media = mp.AudioFileClip(media_path)

    total_duration = int(media.duration)
    parts = total_duration // duration if total_duration % duration == 0 else total_duration // duration + 1
    logger.debug(f"{file_type.capitalize()} total duration: {total_duration} seconds, will be split into {parts} parts")

    for idx in range(1, parts + 1):
        chunk_filename = os.path.join(temp_dir, f"chunk_{idx:02d}.mp3")
        logger.debug(f"Processing part {idx}/{parts} â†’ {chunk_filename}")
        clip = media.subclip((idx - 1) * duration, min(idx * duration, total_duration))

        # Choose the appropriate save method based on media type
        if is_video:
            clip.audio.write_audiofile(chunk_filename, verbose=False, logger=None)
        else:
            clip.write_audiofile(chunk_filename, verbose=False, logger=None)

    logger.info(f"Successfully split {file_type} into {parts} parts")
    media.close()


def save_raw_transcript(transcript_text, output_path, chunk_name):
    """
    Saves the raw transcription result generated by the LLM.

    Args:
        transcript_text (str): The raw transcribed text.
        output_path (str): The target folder path.
        chunk_name (str): The name of the audio chunk.
    """
    # Ensure the output directory exists
    os.makedirs(output_path, exist_ok=True)

    # Generate the output file name
    output_file = os.path.join(output_path, f"{os.path.splitext(chunk_name)[0]}_raw.txt")

    # Write to the file
    with open(output_file, "w", encoding="utf-8") as f:
        f.write(transcript_text)

    logger.debug(f"Raw transcript saved to: {output_file}")
    return output_file


def get_transcription_prompt(extra_prompt=None):
    """
    Creates a transcription prompt template, supporting additional prompts.

    Args:
        extra_prompt (str, optional): Additional prompt content.
    """
    template = """Please transcribe this audio into text, including timestamps.

Each timestamp should be in the format: [MM:SS.ss] or [HH:MM:SS.ss]. Be sure to include seconds after the decimal point, accurate to two decimal places.
For example:
[00:01.25] This is the first sentence. (Indicates 1 second 250 milliseconds)
[00:05.78] This is the second sentence. (Indicates 5 seconds 780 milliseconds)
[01:23.45] This is the third sentence. (Indicates 1 minute 23 seconds 450 milliseconds)

Keep each sentence short for subtitling purposes. Each sentence should have a clear timestamp reflecting the actual start time of speech.
**Important Rules:**
1. The text content of each subtitle line (excluding the timestamp) should be kept reasonably short.
2. Please remove punctuation at the end of each line (e.g., periods, commas, question marks, exclamation marks).

If there is music or sound effects, please notate it as:
[01:02.35] [Music] or [01:02.35] [Sound effect]

Please transcribe using the following language: {language}"""

    # If there's an extra prompt, add it
    if extra_prompt:
        template += f"\n\nAdditionally, here are some extra prompts for your reference:\n{extra_prompt}"

    return PromptTemplate.from_template(template)


def process_single_file(file, idx, duration, lang, model_name, save_raw, raw_dir, extra_prompt=None, time_offset=0,
                        preview=False, max_retries=3):
    """
    Processes the transcription of a single audio file, designed to run in a multi-threaded environment.

    Args:
        file (str): Path to the audio file.
        idx (int): Index of the file.
        duration (int): Segment duration in seconds.
        lang (str): Language code.
        model_name (str): Name of the Gemini model.
        save_raw (bool): Whether to save the raw transcription result.
        raw_dir (str): Directory to store raw transcripts.
        extra_prompt (str, optional): Additional prompt content.
        time_offset (int, optional): Time offset in seconds.
        preview (bool, optional): Whether to display a preview of the raw transcript.
        max_retries (int, optional): Maximum number of retries, default is 3.

    Returns:
        tuple: (SRT formatted subtitle content, path to the raw transcript file)
    """
    basename = os.path.basename(file)
    logger.info(f"Transcribing {basename} (index {idx})...")
    logger.debug(f"Applying time offset: {time_offset} seconds")
    time1 = time.time()

    # Set up the prompt template
    prompt_template = get_transcription_prompt(extra_prompt)

    # Prepare the prompt
    prompt = prompt_template.format(language=lang)
    logger.debug(f"Generated prompt template, language setting: {lang}")

    # Configure the Gemini model
    generation_config = types.GenerateContentConfig(
        temperature=0,
        top_p=1,
        top_k=32,
        max_output_tokens=None
    )

    # Implement retry logic
    retries = 0
    last_error = None

    while retries <= max_retries:
        current_key = None
        try:
            # Randomly select an API KEY and configure it
            try:
                current_key = key_manager.get_key()  # Use the new manager to get a key
                logger.debug(f"Using a randomly selected API KEY (last 6 digits: ...{current_key[-6:]})")
                client = genai.Client(api_key=current_key)
            except ValueError as e:
                # No more available API KEYs
                logger.error(f"Could not get an available API KEY: {e}")
                return None, None

            # First, upload the audio file
            try:
                logger.debug(f"Uploading audio file {file}")
                uploaded_file = client.files.upload(file=file)
                logger.debug(f"Successfully uploaded file {file}")
            except Exception as e:
                logger.error(f"Failed to upload audio file: {e}")
                return None, None

            # Create the model and send the request - modified to use the uploaded file
            response = client.models.generate_content(
                model=model_name,
                contents=[prompt, uploaded_file],
                config=generation_config
            )

            # Get the raw transcribed text
            raw_transcript = response.text
            logger.debug(f"Received response from Gemini API, length: {len(raw_transcript)} characters")

            # Print the raw transcription result (may be long, so only show first 200 and last 200 characters)
            if preview:
                if len(raw_transcript) > 400:
                    preview_text = f"{raw_transcript[:200]}...\n...\n{raw_transcript[-200:]}"
                else:
                    preview_text = raw_transcript

                logger.info(f"Raw transcript preview:\n{preview_text}")

            # Save the raw transcription result
            raw_file = None
            if save_raw:
                raw_file = save_raw_transcript(raw_transcript, raw_dir, basename)
                logger.info(f"Raw transcript has been saved to: {raw_file}")

            # Directly convert the Gemini response to SRT format
            logger.debug(f"Processing transcript result, time offset: {time_offset} seconds")
            srt_content = direct_to_srt(raw_transcript, time_offset)

            if not srt_content:
                logger.error(f"Transcription of {file} failed")
                return None, raw_file

            # Use subtitle entry count instead of newlines for counting
            subtitle_count = srt_content.count("\n\n") if srt_content else 0
            logger.debug(f"Converted transcript to SRT format, estimated subtitle count: {subtitle_count}")

            time2 = time.time()
            processing_time = time2 - time1
            logger.info(f"Finished transcribing {basename}, took {processing_time:.2f} seconds")

            return srt_content, raw_file

        except Exception as e:
            logger.error(f"An error occurred while processing {file}: {e}")
            last_error = e
            error_message = str(e)

            # Check for rate limit error (429)
            if "429" in error_message and current_key:
                logger.warning(f"API KEY rate limit error: {error_message}")
                # Mark the current KEY as exhausted
                if key_manager.disable_key(current_key):  # Use the new manager to disable the key
                    retries -= 1  # If the rate-limited key is successfully removed, don't count it as a retry

            retries += 1

            if retries <= max_retries:
                backoff_time = 2 ** retries  # Exponential backoff strategy
                logger.warning(f"Retrying ({retries}), waiting {backoff_time} seconds...")
                time.sleep(backoff_time)
            else:
                logger.error(f"Error processing {file} after {max_retries} retries: {last_error}")

    # All retries failed
    logger.error(f"Error processing {file}: {last_error}", exc_info=True)
    return None, None


def transcribe_with_gemini(temp_dir, duration=300, max_segment_retries=3, **kwargs):
    """
    Transcribes audio file chunks in parallel using the Gemini model.

    Args:
        temp_dir (str): Temporary directory containing audio chunks.
        duration (int, optional): Duration of each audio chunk in seconds. Defaults to 300.
        max_segment_retries (int, optional): Maximum number of retries for each failed audio chunk transcription. Defaults to 1.
        **kwargs: Other parameters passed to process_single_file, such as:
            lang (str): Transcription language, defaults to 'zh-TW'.
            model (str): Gemini model name.
            save_raw (bool): Whether to save raw transcription results.
            raw_dir (str): Directory to save raw transcription results.
            original_file (str): Path to the original media file, used to generate default raw_dir.
            max_workers (int): Maximum number of worker threads for ThreadPoolExecutor.
            extra_prompt (str): Additional transcription prompt.
            time_offset (int): Overall time offset in seconds.
            preview (bool): Whether to preview raw transcription results.

    Returns:
        list or None: A list of SRT subtitle content if all chunks are transcribed successfully.
                      Returns None if any chunk fails after exhausting all retries.
    """
    lang = kwargs.get("lang", 'zh-TW')
    model_name = kwargs.get("model", "gemini-2.5-flash-preview-05-20")
    save_raw = kwargs.get("save_raw", False)
    raw_dir = kwargs.get("raw_dir", None)
    original_file = kwargs.get("original_file", "unknown")
    max_workers = kwargs.get("max_workers", min(32, (os.cpu_count() or 1) * 5, key_manager.get_available_key_count()))
    extra_prompt = kwargs.get("extra_prompt", None)
    time_offset = kwargs.get("time_offset", 0)
    preview = kwargs.get("preview", False)
    max_segment_retries = kwargs.get("max_segment_retries", 1)

    if raw_dir is None:
        base_dir = os.path.dirname(original_file)
        base_name = os.path.splitext(os.path.basename(original_file))[0]
        raw_dir = os.path.join(base_dir, f"{base_name}_transcripts")

    logger.debug(
        f"Starting transcription process, language: {lang}, model: {model_name}, "
        f"max_workers: {max_workers}, time_offset: {time_offset}s, "
        f"max_segment_retries: {max_segment_retries}"
    )

    all_files = [os.path.join(temp_dir, f) for f in os.listdir(temp_dir) if f.endswith(".mp3")]
    all_files.sort()
    logger.debug(f"Found {len(all_files)} audio files to transcribe")

    if not all_files:
        logger.info("No .mp3 files found in the temporary directory to transcribe.")
        return []

    # Create containers for results
    transcripts_results = [None] * len(all_files)
    raw_transcripts_paths = []

    # Ensure output directory exists
    if save_raw:
        os.makedirs(raw_dir, exist_ok=True)

    # Task definition: (file_path, original_index, current_retry_count, segment_time_offset)
    Task = collections.namedtuple('Task', ['file_path', 'original_index', 'current_retry_count', 'segment_time_offset'])

    tasks_to_process = collections.deque()
    for idx, file_path in enumerate(all_files):
        segment_time_offset = time_offset + (idx * duration)
        tasks_to_process.append(Task(file_path, idx, 0, segment_time_offset))

    active_futures = {}  # future -> Task
    overall_transcription_failed = False

    with concurrent.futures.ThreadPoolExecutor(max_workers=max_workers) as executor:
        while tasks_to_process or active_futures:
            # Submit new tasks (if the thread pool has space and there are pending tasks)
            while tasks_to_process and len(active_futures) < max_workers:
                task = tasks_to_process.popleft()
                logger.debug(
                    f"Submitting task: {os.path.basename(task.file_path)} (index {task.original_index}), attempt {task.current_retry_count + 1}")
                future = executor.submit(
                    process_single_file,
                    task.file_path, task.original_index, duration, lang, model_name,
                    save_raw, raw_dir, extra_prompt, task.segment_time_offset, preview
                )
                active_futures[future] = task

            if not active_futures:  # If no active tasks, break the loop (all tasks are processed)
                break

            # Wait for at least one task to complete
            done, _ = concurrent.futures.wait(active_futures.keys(), return_when=concurrent.futures.FIRST_COMPLETED)

            for future in done:
                task = active_futures.pop(future)  # Remove the completed task from the active list
                original_idx = task.original_index
                file_basename = os.path.basename(task.file_path)

                try:
                    srt_content, raw_file_path = future.result()
                    if srt_content is not None:
                        transcripts_results[original_idx] = srt_content
                        if raw_file_path:
                            raw_transcripts_paths.append(raw_file_path)
                        if task.current_retry_count > 0:
                            logger.info(
                                f"Segment {file_basename} (index {original_idx}) transcribed successfully on attempt {task.current_retry_count + 1}.")
                        else:
                            logger.debug(
                                f"Segment {file_basename} (index {original_idx}) transcribed successfully on the first attempt.")
                    else:
                        # srt_content is None means process_single_file determined failure
                        raise Exception("process_single_file returned None, indicating transcription failure")

                except Exception as e:
                    logger.warning(
                        f"Segment {file_basename} (index {original_idx}) transcription attempt {task.current_retry_count + 1} failed. Error: {e}"
                    )
                    if task.current_retry_count < max_segment_retries:
                        new_task = Task(task.file_path, original_idx, task.current_retry_count + 1,
                                        task.segment_time_offset)
                        tasks_to_process.append(new_task)  # Re-queue for retry
                        logger.info(
                            f"Preparing to retry segment {file_basename} (index {original_idx}), attempt {new_task.current_retry_count + 1} of {max_segment_retries + 1}."
                        )
                    else:
                        logger.error(
                            f"Segment {file_basename} (index {original_idx}) failed to transcribe after {max_segment_retries + 1} attempts. Final error: {e}. Aborting the entire transcription process."
                        )
                        overall_transcription_failed = True
                        # Trigger abortion
                        break

            if overall_transcription_failed:
                break  # Break out of the main while loop

        if overall_transcription_failed:
            logger.error(
                "Overall transcription task aborted due to a segment failing permanently. Cancelling remaining tasks...")
            # Cancel all remaining futures (if the executor is still running)
            # executor.shutdown(wait=False, cancel_futures=True) # in Python 3.9+
            # For compatibility, we cancel manually
            for future_to_cancel in list(active_futures.keys()):  # Use list for a copy as the dict will be modified
                future_to_cancel.cancel()
                active_futures.pop(future_to_cancel, None)  # Remove from active_futures
            # Clear pending tasks
            tasks_to_process.clear()
            logger.info("All remaining transcription tasks have been requested to cancel.")
            return None

    # If execution reaches here, all segments were successful (or all_files was empty)
    if not all_files:  # Handle the case of an empty file list
        return []

    # Check for any remaining None values (should not happen in theory, as failure returns None early)
    if any(t is None for t in transcripts_results):
        logger.error(
            "Transcription complete, but the results list contains None values, which is unexpected. Please check the logic.")
        # Even if this happens, try to return the successful results
        successful_transcripts = [t for t in transcripts_results if t is not None]
        if not successful_transcripts:  # If all are None after filtering, return None
            logger.error("All transcription results are None, returning None.")
            return None
        logger.warning(f"Returning {len(successful_transcripts)} partially successful transcription results.")
        return successful_transcripts

    logger.info(f"All audio files transcribed, total of {len(transcripts_results)} successful results.")

    if save_raw and raw_transcripts_paths:
        combined_raw_file = os.path.join(raw_dir, "combined_raw.txt")
        raw_transcripts_paths.sort()  # Ensure order when merging
        with open(combined_raw_file, "w", encoding="utf-8") as f:
            for idx, raw_file in enumerate(raw_transcripts_paths):
                try:
                    with open(raw_file, "r", encoding="utf-8") as rf:
                        f.write(
                            f"=== Chunk from file: {os.path.basename(raw_file)} (original order {idx + 1}) ===\n")  # More explicit header
                        f.write(rf.read())
                        f.write("\n\n")
                except Exception as e:
                    logger.error(f"Error merging raw transcript file {raw_file}: {e}")
        logger.info(f"All raw transcripts have been merged into: {combined_raw_file}")

    return transcripts_results


def direct_to_srt(transcript_text, time_offset=0):
    """
    Directly converts the Gemini transcription result to SRT format.

    Args:
        transcript_text (str): The text transcribed by Gemini.
        time_offset (int): Time offset in seconds.

    Returns:
        str: Subtitle content in SRT format.
    """
    try:
        logger.debug(f"Starting conversion of transcript text to SRT format, time offset: {time_offset} seconds")
        lines = transcript_text.strip().splitlines()
        logger.debug(f"Transcript text contains {len(lines)} lines")

        srt_lines = []
        srt_index = 1

        # Match timestamp and text content - supports precise timestamps (with milliseconds)
        # Match format: [HH:MM:SS.ss] or [MM:SS.ss]
        line_regex = re.compile(r'^\[((?:\d{2}:)?\d{2}:\d{2}(?:\.\d+)?)\]\s*(.+)$')

        matched_count = 0
        skipped_count = 0

        # Store previous timestamp to calculate duration
        prev_timestamp_seconds = None

        for i, line in enumerate(lines):
            line = line.strip()
            if not line:
                skipped_count += 1
                continue

            match = line_regex.match(line)
            if not match:
                logger.debug(
                    f"Line {i + 1} does not match timestamp format: {line[:50] + ('...' if len(line) > 50 else '')}")
                skipped_count += 1
                continue

            timestamp, content = match.groups()
            seconds = timestamp_to_seconds(timestamp)

            if seconds is None:
                logger.warning(f"Line {i + 1} timestamp parsing failed: {timestamp}")
                skipped_count += 1
                continue

            # Apply time offset
            seconds += time_offset

            # Calculate end time
            # 1. Check if the next line exists and has a valid timestamp; if so, use it as the end time.
            # 2. Otherwise, use a default duration (typically 3-5 seconds).
            next_timestamp_seconds = None
            default_duration = 3.0  # Default duration in seconds

            # Find the next valid timestamp
            for next_line in lines[i + 1:]:
                next_match = line_regex.match(next_line.strip())
                if next_match:
                    next_timestamp, _ = next_match.groups()
                    next_timestamp_seconds = timestamp_to_seconds(next_timestamp)
                    if next_timestamp_seconds is not None:
                        next_timestamp_seconds += time_offset
                        break

            # Determine the end time
            if next_timestamp_seconds is not None:
                end_time = next_timestamp_seconds
                # Ensure a minimum duration of 0.5 seconds
                if end_time - seconds < 0.5:
                    end_time = seconds + 0.5
            else:
                # If there's no next timestamp, use the default duration
                end_time = seconds + default_duration

            # Ensure the timestamp includes the fractional part to maintain millisecond precision
            start_formatted = format_time_srt(seconds)
            end_formatted = format_time_srt(end_time)

            srt_lines.append(f"{srt_index}")
            srt_lines.append(f"{start_formatted} --> {end_formatted}")
            srt_lines.append(f"{content}")
            srt_lines.append("")  # Blank line separator

            srt_index += 1
            matched_count += 1

            # Update the previous timestamp
            prev_timestamp_seconds = seconds

        logger.debug(
            f"SRT conversion complete: total_lines={len(lines)}, matched={matched_count}, skipped={skipped_count}")
        return "\n".join(srt_lines)
    except Exception as e:
        logger.error(f"Error converting to SRT format: {e}", exc_info=True)
        return None


def timestamp_to_seconds(ts_str):
    """
    Converts a timestamp string in HH:MM:SS.ss or MM:SS.ss format to total seconds.
    Supports millisecond precision.

    Args:
        ts_str (str): Timestamp string in HH:MM:SS.ss or MM:SS.ss format.

    Returns:
        float or None: Total seconds (including fractional part), or None if parsing fails.
    """
    try:
        # Check for a decimal point
        ms_part = 0.0
        if '.' in ts_str:
            main_part, ms_part_str = ts_str.split('.')
            ms_part = float('0.' + ms_part_str)
        else:
            main_part = ts_str

        # Split the timestamp into parts
        parts = list(map(int, main_part.split(':')))

        if len(parts) == 3:  # HH:MM:SS format
            h, m, s = parts
            return h * 3600 + m * 60 + s + ms_part
        elif len(parts) == 2:  # MM:SS format
            m, s = parts
            return m * 60 + s + ms_part
        else:
            # Invalid number of parts
            return None
    except (ValueError, AttributeError, IndexError) as e:
        logger.debug(f"Timestamp parsing failed: {ts_str}, error: {e}")
        return None


def format_time_srt(seconds):
    """
    Formats seconds into an SRT timestamp (HH:MM:SS,mmm).

    Args:
        seconds (float): Number of seconds.

    Returns:
        str: Timestamp in SRT format.
    """
    if seconds is None or seconds < 0:
        seconds = 0.0  # Default to 0 if input is invalid or negative

    # Calculate hours, minutes, and seconds
    hours = int(seconds // 3600)
    minutes = int((seconds % 3600) // 60)
    secs = int(seconds % 60)

    # Get the millisecond part (keeping 3 digits of precision)
    milliseconds = int((seconds % 1) * 1000)
    return f"{hours:02}:{minutes:02}:{secs:02},{milliseconds:03}"


def combine_subtitles(subtitles):
    """
    Simply combines multiple subtitle files, maintaining correct index numbering.

    Args:
        subtitles (list): A list of subtitle contents.

    Returns:
        str: The combined subtitle content.
    """
    logger.debug(f"Starting to combine {len(subtitles)} subtitle files")
    result = []
    current_idx = 1
    total_entries = 0

    for subtitle_idx, subtitle in enumerate(subtitles):
        logger.debug(f"Processing subtitle file {subtitle_idx + 1}, length: {len(subtitle)} characters")
        lines = subtitle.splitlines()
        i = 0
        subtitle_entries = 0

        while i < len(lines):
            if not lines[i].strip():
                i += 1
                continue

            # Check if it's an index line (purely numeric)
            if lines[i].strip().isdigit() and i + 2 < len(lines):
                # Replace the index with the correct current index
                result.append(str(current_idx))
                result.append(lines[i + 1])  # Time line
                result.append(lines[i + 2])  # Text line
                result.append("")  # Blank line
                current_idx += 1
                subtitle_entries += 1
                i += 3
            else:
                i += 1

        total_entries += subtitle_entries
        logger.debug(f"Finished processing subtitle file {subtitle_idx + 1}, contains {subtitle_entries} entries")

    logger.info(f"Subtitle combination complete, total of {total_entries} entries")
    return "\n".join(result)


def main(video_path, skip_existing=False, **kwargs):
    duration = kwargs.get("duration", 300)
    lang = kwargs.get("lang", 'zh-TW')
    model = kwargs.get("model", "gemini-2.5-flash-preview-05-20")
    save_raw = kwargs.get("save_raw", False)
    max_workers = kwargs.get("max_workers", min(32, (os.cpu_count() or 1) * 5, key_manager.get_available_key_count()))
    extra_prompt = kwargs.get("extra_prompt", None)
    time_offset = kwargs.get("time_offset", 0)  # Get time offset, default is 0
    max_segment_retries = kwargs.get("max_segment_retries", 1)  # Default to 1 if not provided

    logger.debug(
        f"Processing parameters: duration={duration}s, lang={lang}, model={model}, save_raw={save_raw}, max_workers={max_workers}, skip_existing={skip_existing}, time_offset={time_offset}s, max_segment_retries={max_segment_retries}")

    _, ext = os.path.splitext(video_path)
    output_file = video_path.replace(ext, ".srt")

    # Check if SRT file exists and skip if requested
    if skip_existing and os.path.exists(output_file):
        logger.info(f"Subtitle file '{output_file}' already exists, skipping processing for '{video_path}'")
        return

    with tempfile.TemporaryDirectory() as temp_dir:
        logger.debug(f"Created temporary directory: {temp_dir}")
        if ext.lower() in [".mp4", ".avi", ".mkv"]:
            logger.info("Video file detected, starting to split audio")
            split_media(video_path, temp_dir, duration=duration)
        elif ext.lower() in [".mp3", ".wav"]:
            logger.info("Audio file detected, starting to split")
            split_media(video_path, temp_dir, duration=duration)
        else:
            logger.error(f"Unsupported file format: {ext}")
            return

        logger.info("Starting multi-threaded transcription process...")
        subs = transcribe_with_gemini(temp_dir, duration=duration, lang=lang, model=model,
                                      save_raw=save_raw, original_file=video_path,
                                      max_workers=max_workers,
                                      extra_prompt=extra_prompt,
                                      time_offset=time_offset,
                                      max_segment_retries=max_segment_retries)  # Pass max_segment_retries

        if not subs:
            logger.error("Transcription failed, no subtitles were generated")
            return

        logger.info("Starting to combine subtitles...")
        combined_subs = combine_subtitles(subs)

        logger.debug(f"Writing subtitle file: {output_file}")
        with open(output_file, "w", encoding="utf-8") as file:
            file.write(combined_subs)
        logger.info(f"Subtitles saved to {output_file}")


def clip(filepath, st=None, ed=None):
    """
    Clips a specified section of a video and extracts the audio.

    Args:
        filepath (str): Path to the video file.
        st (int, optional): Start time in seconds.
        ed (int, optional): End time in seconds.

    Returns:
        str: Path to the output audio file.
    """
    logger.info(f"Preparing to clip video: {filepath}")
    logger.debug(f"Clipping range: start={st if st is not None else 'start'}, end={ed if ed is not None else 'end'}")

    clip = mp.VideoFileClip(filepath)
    logger.debug(f"Original video duration: {clip.duration:.2f} seconds")

    if st is not None or ed is not None:
        if st is None:
            st = 0
        if ed is None:
            ed = int(clip.duration)
        logger.info(f"Clipping video, range: {st}-{ed} seconds")
        clip = clip.subclip(st, ed)
        newpath = filepath.replace(".mp4", f"_{st}-{ed}.mp3")
    else:
        logger.info("Extracting audio from the full video")
        newpath = filepath.replace(".mp4", ".mp3")

    logger.debug(f"Starting to extract audio to: {newpath}")
    clip.audio.write_audiofile(newpath, verbose=False, logger=None)
    logger.info(f"Audio extraction complete: {newpath}")
    clip.close()
    return newpath


def clip_and_transcribe(filepath, st=None, ed=None, skip_existing=False, **kwargs):
    """
    Clips a video and then transcribes it.

    Args:
        filepath (str): Path to the video file.
        st (int, optional): Start time in seconds.
        ed (int, optional): End time in seconds.
        skip_existing (bool): Whether to skip if the SRT file already exists.
    """
    logger.info(f"Starting to clip and transcribe: {filepath}")

    # Check based on the original filepath's expected SRT name
    _, ext = os.path.splitext(filepath)
    output_srt_path = filepath.replace(ext, ".srt")
    if skip_existing and os.path.exists(output_srt_path):
        logger.info(f"Subtitle file '{output_srt_path}' already exists, skipping clip and transcribe for '{filepath}'")
        return

    if st is None:
        st = 0
    newpath = clip(filepath, st, ed)
    logger.debug(f"Starting transcription of clipped audio: {newpath}")

    # Pass the original start time as a parameter for timestamp correction
    kwargs['time_offset'] = st
    logger.debug(f"Setting time offset: {st} seconds, to correct subtitle timestamps")

    # Pass skip_existing=False here, as the check was already done based on the *original* filename
    # Or pass skip_existing=skip_existing if main should re-check based on the newpath (less likely desired)
    main(newpath, **kwargs)  # Pass kwargs explicitly


def process_directory(directory_path, skip_existing=False, **kwargs):
    """
    Processes all video and audio files in a directory, including subdirectories.

    Args:
        directory_path (str): Path to the directory.
        skip_existing (bool): Whether to skip if the SRT file already exists.
        **kwargs: Arguments to pass to the main or clip_and_transcribe functions.
    """
    logger.info(f"Processing directory (including subdirectories): {directory_path}")

    # Supported file types
    video_extensions = [".mp4", ".avi", ".mkv"]
    audio_extensions = [".mp3", ".wav"]
    supported_extensions = video_extensions + audio_extensions

    files = []
    for root, _, filenames in os.walk(directory_path):
        for filename in filenames:
            filepath = os.path.join(root, filename)
            _, ext = os.path.splitext(filename)
            if ext.lower() in supported_extensions:
                # Avoid processing generated SRT files
                if ext.lower() != ".srt":
                    files.append(filepath)

    if not files:
        logger.warning("No supported video or audio files found in the directory and its subdirectories")
        return

    logger.info(f"Found {len(files)} supported files in the directory and its subdirectories")

    # Process each file sequentially
    for i, filepath in enumerate(files):
        logger.info(f"Processing file {i + 1}/{len(files)}: {filepath}")

        # Determine the expected SRT path for the current file
        _, ext = os.path.splitext(filepath)
        output_srt_path = filepath.replace(ext, ".srt")

        # Check if skipping is needed
        if skip_existing and os.path.exists(output_srt_path):
            logger.info(f"Subtitle file '{output_srt_path}' already exists, skipping processing for '{filepath}'")
            continue  # Skip to the next file

        # Extract relevant kwargs for main/clip_and_transcribe
        common_kwargs = {
            "duration": kwargs.get("duration", 300),
            "lang": kwargs.get("lang", 'zh-TW'),
            "model": kwargs.get("model", "gemini-2.5-flash-preview-05-20"),
            "save_raw": kwargs.get("save_raw"),
            "max_workers": kwargs.get("max_workers", min(32, (os.cpu_count() or 1) * 5)),
            "extra_prompt": kwargs.get("extra_prompt"),
            "max_segment_retries": kwargs.get("max_segment_retries", 1),  # Added max_segment_retries
        }

        # Check if clipping is needed
        start_time = kwargs.get("start")
        end_time = kwargs.get("end")
        if start_time is not None or end_time is not None:
            # Ensure start time has a value for timestamp correction
            if start_time is None:
                start_time = 0
            logger.debug(f"Will use time offset of {start_time} seconds for transcription")
            clip_and_transcribe(filepath, st=start_time, ed=end_time,
                                skip_existing=skip_existing,  # skip_existing is passed to clip_and_transcribe
                                **common_kwargs)
        else:
            # Pass skip_existing to main as well, though its own check will be based on the input filepath
            main(filepath, skip_existing=skip_existing, **common_kwargs)

    logger.info("Directory processing complete")


if __name__ == "__main__":
    parser = argparse.ArgumentParser(description="Generate subtitles for video or audio using Google Gemini")
    parser.add_argument("-i", "--input", help="Input video, audio file, or a folder containing media files",
                        required=True)
    parser.add_argument("-d", "--duration", help="Duration of each segment in seconds", type=int, default=900)
    parser.add_argument("-l", "--lang", help="Language code", default="zh-TW")
    parser.add_argument("-m", "--model", help="Gemini model", default="gemini-2.5-flash-preview-05-20")
    parser.add_argument("--start", help="Start time in seconds", type=int)
    parser.add_argument("--end", help="End time in seconds", type=int)
    parser.add_argument("--save-raw", help="Save the raw transcription result", action="store_true")
    parser.add_argument("--skip-existing", help="Skip processing if the SRT subtitle file already exists",
                        action="store_true")
    parser.add_argument("--debug", help="Enable DEBUG level logging", action="store_true")
    parser.add_argument("--max-workers",
                        help="Maximum number of worker threads (cannot exceed the number of GOOGLE_API_KEYS by default)",
                        type=int, default=min(32, (os.cpu_count() or 1) * 5))
    parser.add_argument("--extra-prompt", help="Additional prompt or a path to a file containing the prompt", type=str)
    parser.add_argument("--ignore-keys-limit", help="Ignore the limit on max_workers imposed by the number of API keys",
                        action="store_true")
    parser.add_argument("--preview", help="Display a preview of the raw transcription result", action="store_true")
    parser.add_argument("--max-segment-retries",
                        help="Maximum number of retries for each failed audio chunk transcription", type=int, default=3)
    args = parser.parse_args()

    # Set logging level
    log_level = logging.DEBUG if args.debug else logging.INFO
    setup_logging(log_level)

    logger.info("Gemini ASR Transcription Service starting")
    logger.info(f"Loaded {key_manager.get_available_key_count()} API KEYs")
    if not args.ignore_keys_limit:
        args.max_workers = min(args.max_workers, key_manager.get_available_key_count())
    logger.info(f"Parallel transcription setting: max_workers={args.max_workers}")

    extra_prompt_value = args.extra_prompt
    if extra_prompt_value and os.path.isfile(extra_prompt_value):
        try:
            with open(extra_prompt_value, 'r', encoding='utf-8') as f:
                extra_prompt_value = f.read().strip()
            logger.info(f"Read extra prompt from file '{args.extra_prompt}'.")
        except Exception as e:
            logger.warning(f"Could not read prompt file '{args.extra_prompt}': {e}. The extra prompt will be ignored.")
            extra_prompt_value = None
    if extra_prompt_value:
        logger.info(f"Using extra prompt:\n{extra_prompt_value}")

    # Create a dictionary of arguments to pass to functions
    func_kwargs = {
        "duration": args.duration,
        "lang": args.lang,
        "model": args.model,
        "save_raw": args.save_raw,
        "max_workers": args.max_workers,
        "extra_prompt": extra_prompt_value,
        "skip_existing": args.skip_existing,
        "preview": args.preview,
        "max_segment_retries": args.max_segment_retries,
    }

    # Check if the input is a directory
    if os.path.isdir(args.input):
        logger.info("Input is a directory, will process all supported media files within")
        # Pass start and end for directory processing
        process_directory(args.input, start=args.start, end=args.end, **func_kwargs)
    else:
        # Original logic for processing a single file
        if args.start is not None or args.end is not None:
            clip_and_transcribe(args.input, st=args.start, ed=args.end, **func_kwargs)
        else:
            main(args.input, **func_kwargs)

    logger.info("Processing complete")